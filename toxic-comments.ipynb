{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TUwHiMEkgr4V",
    "outputId": "cd6e8ce8-362e-41f4-c5d0-4b137eba7ba1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.12 / client 1.5.4)\n",
      "Downloading train.csv.zip to /content\n",
      " 65% 17.0M/26.3M [00:00<00:00, 76.0MB/s]\n",
      "100% 26.3M/26.3M [00:00<00:00, 87.7MB/s]\n",
      "Downloading test_labels.csv.zip to /content\n",
      "  0% 0.00/1.46M [00:00<?, ?B/s]\n",
      "100% 1.46M/1.46M [00:00<00:00, 99.4MB/s]\n",
      "Downloading sample_submission.csv.zip to /content\n",
      "  0% 0.00/1.39M [00:00<?, ?B/s]\n",
      "100% 1.39M/1.39M [00:00<00:00, 204MB/s]\n",
      "Downloading test.csv.zip to /content\n",
      " 38% 9.00M/23.4M [00:00<00:00, 92.6MB/s]\n",
      "100% 23.4M/23.4M [00:00<00:00, 150MB/s] \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import zipfile\n",
    "\n",
    "\n",
    "os.environ['KAGGLE_USERNAME'] = \"\"\n",
    "os.environ['KAGGLE_KEY'] = \"\"\n",
    "!kaggle competitions download -c jigsaw-toxic-comment-classification-challenge\n",
    "\n",
    "for filename in os.listdir():\n",
    "    if filename.endswith(\".zip\"):\n",
    "        zip_ref = zipfile.ZipFile(filename)\n",
    "        zip_ref.extractall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rXr979UXrI1e"
   },
   "source": [
    "Рассмотрим данные из соревнования с kaggle [toxic comment classification challenge](https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge), тк задача хорошо нам подходит - классификация текстов. Будем классифицировать комментарии только по одному критерию - toxic/non-toxic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "X8ACJJZSh_f0"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.random.seed(0xFFFFFFF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "y94v-_hfiVyx"
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('./train.csv')\n",
    "test = pd.read_csv('./test.csv')\n",
    "test_labels = pd.read_csv('./test_labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "ALesuaZcYrMA"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "TOHYNVJIZjYI"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "571ZW4uALxma"
   },
   "outputs": [],
   "source": [
    "df = train.copy()\n",
    "rslt_df = df[(df['toxic'] == 0) & (df['severe_toxic'] == 0) & (df['obscene'] == 0) & (df['threat'] == 0) & (df['insult'] == 0) & (df['identity_hate'] == 0)]\n",
    "rslt_df2 = df[(df['toxic'] == 1) | (df['severe_toxic'] == 1) | (df['obscene'] == 1) | (df['threat'] == 1) | (df['insult'] == 1) | (df['identity_hate'] == 1)]\n",
    "# Примерно сохраняем изначальную пропорцию классов\n",
    "new1 = rslt_df[['id', 'comment_text', 'toxic']].iloc[:23891].copy() \n",
    "new2 = rslt_df2[['id', 'comment_text', 'toxic']].iloc[:946].copy()\n",
    "new = pd.concat([new1, new2], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "D5oiPb2hL77m"
   },
   "outputs": [],
   "source": [
    "# Тк toxic комментариев мало, будем делить на трейн/тест выборки с сохранением соотношения.\n",
    "X_train, X_test, y_train, y_test = train_test_split(new[\"comment_text\"], new['toxic'], test_size=0.33, stratify=new['toxic'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "COE9hRO6L82X"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1, 2), max_df=0.95, min_df=5)\n",
    "X1 = vectorizer.fit_transform(X_train)\n",
    "X_test1= vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Nl6qTPaptqSC"
   },
   "source": [
    "Для начала сравним ядровой СВМ и логистическую регрессию. Сравнение будем проводить по доле верных ответов и метрике F1, тк классы несбалансированные.\n",
    "Ядровой СВМ побеждает."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f1U5lzKOMFd8",
    "outputId": "bb69eedb-2613-4a93-d04d-0400fcd4bb46"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.976577\n",
      "F1 score: 0.522388\n"
     ]
    }
   ],
   "source": [
    "clf2 = svm.SVC(kernel='linear', C=1,probability=True)\n",
    "y_p1 = clf2.fit(X1, y_train).predict(X_test1)\n",
    "accuracy = accuracy_score(y_test, y_p1)\n",
    "print('Accuracy: %f' % accuracy)\n",
    "print('F1 score: %f' % f1_score(y_test, y_p1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "26KbFH21NLVt",
    "outputId": "be19265e-843a-4bb5-a296-6bb806854844"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.970233\n",
      "F1 score: 0.290698\n"
     ]
    }
   ],
   "source": [
    "clf4 = LogisticRegression()\n",
    "clf4.fit(X1, y_train)\n",
    "y_p1 = clf4.predict(X_test1)\n",
    "accuracy = accuracy_score(y_test, y_p1)\n",
    "print('Accuracy: %f' % accuracy)\n",
    "print('F1 score: %f' % f1_score(y_test, y_p1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UJg5tYNguNJ1"
   },
   "source": [
    "Теперь сравним с более сильным противником - градиентный бустинг. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QBnICSQfNZM5",
    "outputId": "d138a245-a9b7-4014-af06-5cb7728cb847"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': 0.2682695795279725, 'n_estimators': 250}\n",
      "xgboost accuracy: 0.9766987922410638\n",
      "xgboost f1: 0.5352798053527981\n"
     ]
    }
   ],
   "source": [
    "param_grid = {'learning_rate': np.logspace(-2., 0., num=8),\n",
    "              'n_estimators':[150, 200, 250],\n",
    "             }\n",
    "\n",
    "clf3 = GridSearchCV(xgb.XGBClassifier(), param_grid, scoring=\"accuracy\")\n",
    "\n",
    "clf3.fit(X1, y_train)\n",
    "print(clf3.best_params_)\n",
    "y_pred = clf3.predict(X_test1)\n",
    "print(\"xgboost accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"xgboost f1:\", f1_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l8V-xGqGfFY_"
   },
   "source": [
    "Тк видим, что число базовых моделей получилось максимально возможным, проверим, что будет для бОльших значемний. Видим, что лучший результат получился хуже."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dVEJkj8C5cq6",
    "outputId": "d3c8d2c3-d568-4d5c-f7e7-93b875314258"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': 0.2682695795279725, 'n_estimators': 350}\n",
      "xgboost accuracy: 0.9762108088324997\n",
      "xgboost f1: 0.5323741007194245\n"
     ]
    }
   ],
   "source": [
    "param_grid = {'learning_rate': np.logspace(-2., 0., num=8),\n",
    "              'n_estimators':[300, 350],\n",
    "             }\n",
    "\n",
    "clf3 = GridSearchCV(xgb.XGBClassifier(), param_grid, scoring=\"accuracy\")\n",
    "\n",
    "clf3.fit(X1, y_train)\n",
    "print(clf3.best_params_)\n",
    "y_pred = clf3.predict(X_test1)\n",
    "print(\"xgboost accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"xgboost f1:\", f1_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UFM9PrKlrOj2",
    "outputId": "3f893db4-d40c-45ba-db6c-ddf6d1ec9e71"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 2.5118864315095797, 'kernel': 'sigmoid', 'probability': True}\n",
      "SVC accuracy: 0.9781627424667562\n",
      "SVC f1: 0.5941043083900227\n"
     ]
    }
   ],
   "source": [
    "param_grid = {'C': np.logspace(-2., 1., num=6),\n",
    "              'kernel':['sigmoid'],\n",
    "              'probability':[True]\n",
    "             }\n",
    "clf5 = GridSearchCV(svm.SVC(), param_grid, scoring=\"accuracy\")\n",
    "clf5.fit(X1, y_train)\n",
    "print(clf5.best_params_)\n",
    "y_pred = clf5.predict(X_test1)\n",
    "print(\"SVC accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"SVC f1:\", f1_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6I7bHKHEuKu2"
   },
   "source": [
    "{'C': 2.5118864315095797, 'kernel': 'sigmoid', 'probability': True}\n",
    "SVC accuracy: 0.9781627424667562\n",
    "SVC f1: 0.5941043083900227"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iYNUk2KMrO4W",
    "outputId": "037d6f5c-4e72-4e34-acb5-31c94e47e973"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 3.727593720314938, 'kernel': 'linear', 'probability': True}\n",
      "SVC accuracy: 0.977918750762474\n",
      "SVC f1: 0.6004415011037527\n"
     ]
    }
   ],
   "source": [
    "param_grid = {'C': np.logspace(-2., 1., num=8),\n",
    "              'kernel':['linear'],\n",
    "              'probability':[True]\n",
    "             }\n",
    "clf5 = GridSearchCV(svm.SVC(), param_grid, scoring=\"accuracy\")\n",
    "clf5.fit(X1, y_train)\n",
    "print(clf5.best_params_)\n",
    "y_pred = clf5.predict(X_test1)\n",
    "print(\"SVC accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"SVC f1:\", f1_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0A2owe99fhbO"
   },
   "source": [
    "Получается, что линейное и сигмоидное ядро дают результат лучше, чем бустинг. Сравним время на оптимальных параметрах.\n",
    "\n",
    "В нашем случае получилось, что ядровые методы медленнее, но дают заметно лучшее качество."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aBqJ2NJO5dOb",
    "outputId": "ed01ea13-ae62-46a5-e2ca-a20720f394b8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC time: 105.98542904853821\n",
      "SVC accuracy: 0.977918750762474\n",
      "SVC f1: 0.6004415011037527\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "start = time.time()\n",
    "clf_svm = svm.SVC(C=3.727593720314938, kernel='linear', probability=True)\n",
    "clf_svm.fit(X1, y_train)\n",
    "y_pred = clf_svm.predict(X_test1)\n",
    "print(\"SVC time:\", time.time() - start)\n",
    "print(\"SVC accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"SVC f1:\", f1_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JTlhrtiYhOh2",
    "outputId": "7c902dc6-3b15-43f6-883b-6b5503a98bbc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC time: 82.99676513671875\n",
      "SVC accuracy: 0.9781627424667562\n",
      "SVC f1: 0.5941043083900227\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "start = time.time()\n",
    "clf_svm = svm.SVC(C=2.5118864315095797, kernel='sigmoid', probability=True)\n",
    "clf_svm.fit(X1, y_train)\n",
    "y_pred = clf_svm.predict(X_test1)\n",
    "print(\"SVC time:\", time.time() - start)\n",
    "print(\"SVC accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"SVC f1:\", f1_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rDPks7QZ5_S6",
    "outputId": "9b8df31a-221c-4894-bb9b-f7bfcf4ac5cf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGB time: 27.400084018707275\n",
      "XGB accuracy: 0.9766987922410638\n",
      "XGB f1: 0.5352798053527981\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "clf_xgb = xgb.XGBClassifier(learning_rate=0.2682695795279725, n_estimators=250)\n",
    "clf_xgb.fit(X1, y_train)\n",
    "y_pred = clf_xgb.predict(X_test1)\n",
    "print(\"XGB time:\", time.time() - start)\n",
    "print(\"XGB accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"XGB f1:\", f1_score(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "kernels.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
